---
layout: single
title: "Reproducibility Guide: Meta-analysis on MDMA for PTSD"
output:
  md_document:
    variant: markdown_github
    preserve_yaml: true
---

This document provides a comprehensive walk-through of the meta-analysis investigating the efficacy of MDMA for treating PTSD symptoms, using data extracted for the SYPRES project.
The analysis includes both continuous (PTSD symptom severity scores) and dichotomous (response/remission rates) outcomes, along with extensive subgroup and sensitivity analyses.

Our database for this analysis can be accessed through the R package `metapsyData`.
It can also be downloaded directly as a CSV file [here](https://github.com/metapsy-project/data-ptsd-mdmactr/blob/master/data.csv).
Documentation on `metapsyData` is available [here](https://data.metapsy.org).

The meta-analytic portion of this script primarily uses the R package `metapsyTools`.
Documentation on `metapsyTools` is available [here](https://tools.metapsy.org).

This walk-through has some code chunks hidden for clarity.
Full source code for this analysis is available [here](https://github.com/pennlinc/sypres-docs/blob/main/analysis/mdmaptsd/mdma-metanalysis.Rmd).

## Overview

This meta-analysis synthesizes evidence from randomized controlled trials examining the efficacy of MDMA for treating PTSD.
The analysis employs meta-analytic methods to provide robust estimates of treatment effects while accounting for study heterogeneity and potential biases.

### Key Features of This Analysis

- **Comprehensive outcome assessment**: Both continuous (PTSD symptom severity) and dichotomous (response/remission) outcomes
- **Dose-response analysis**: Three-level hierarchical models to examine treatment effects with respect to dosing
- **Co-morbid depression**: Analysis of self-reported depression symptoms in PTSD
- **Robustness testing**: Extensive sensitivity analyses
- **Publication bias assessment**: Multiple methods to evaluate potential bias
- **Transparent reporting**: Complete code and methodology documentation

## Methods

### Key statistical specifications:

- **Effect size**: Hedges' g for continuous outcomes, log RR for dichotomous outcomes
- **Heterogeneity estimator**: REML for random-effects models
- **Confidence intervals**: Q-Profile method for heterogeneity, Knapp-Hartung adjustment for effect sizes
- **Significance testing**: Knapp-Hartung adjustment for small sample sizes

### Quality Assessment

Risk of bias was evaluated using the Cochrane Risk of Bias 2.0 tool.
Publication bias is evaluated using a funnel plot and Egger's test.

```{r setup knitr, include=FALSE}
# Resolve project root robustly when knitting from either repository root
# or from within `analysis/mdmaptsd/`.
root_candidates <- c(
  getwd(),
  normalizePath(file.path(getwd(), ".."), winslash = "/", mustWork = FALSE),
  normalizePath(file.path(getwd(), "..", ".."), winslash = "/", mustWork = FALSE)
)
root_matches <- root_candidates[dir.exists(file.path(root_candidates, "analysis", "mdmaptsd"))]
basedir <- if (length(root_matches) > 0) {
  normalizePath(root_matches[1], winslash = "/", mustWork = TRUE)
} else {
  normalizePath(getwd(), winslash = "/", mustWork = TRUE)
}

knitr::opts_knit$set(
  base.dir = basedir,
  base.url = "/"
)
knitr::opts_chunk$set(
  fig.path = "analysis/mdmaptsd/knitfigs/",
  echo = TRUE
)
```

### Load Required Packages

We begin by loading the necessary R packages for data manipulation, meta-analysis, and visualization:

- **Data manipulation**: `readr` and `tidyverse` for data loading and manipulation
- **Meta-analysis**: `meta` and `metafor` for conducting meta-analytic calculations
- **Effect sizes**: `esc` for effect size calculation utilities
- **Specialized tools**: `metapsyTools` for specific meta-analysis functions and `dmetar` for additional meta-analysis tools

```{r packages, results='hide', message=FALSE, warning=FALSE}
library(readr)
library(tidyverse)
library(meta)
library(metafor)
library(metapsyTools)
library(metapsyData)
library(gt)
library(dmetar)
library(bayesmeta)
```

### Data Loading and Quality Checks

The sypres database `ptsd-mdmactr` is downloaded using the `metapsyData` package.
Before proceeding with the analysis, we perform quality checks to ensure data integrity and identify potential issues.

```{r load data, results=FALSE, message=FALSE}
# # Load data using metapsyData
# d <- getData("ptsd-mdmactr")
# data <- d$data
#
#
# # Check data format with checkDataFormat
# checkDataFormat(data)
#
# # Check conflicts with checkConflicts
# checkConflicts(data,
#   vars.for.id = c(
#     "study", "outcome_type",
#     "instrument", "study_time_point",
#     "time_weeks",
#     "rating"
#   )
# )
data <- read_csv2("~/Documents/GIT/data-ptsd-mdmactr/data.csv") # for parker
# data <- read_csv2("/Users/bsevchik/Documents/GitHub/data-ptsd-mdmactr/data.csv") # for brooke
data <- data %>%
  calculateEffectSizes(
    vars.for.id = c(
      "study", "outcome_type",
      "instrument", "study_time_point",
      "time_weeks",
      "rating"
    ),
  )

# Check data format with checkDataFormat
checkDataFormat(data)

# Check conflicts with checkConflicts
checkConflicts(data,
  vars.for.id = c(
    "study", "outcome_type",
    "instrument", "study_time_point",
    "time_weeks",
    "rating"
  )
)
```

### Data Preparation and Filtering

We prepare the data for analysis by applying several filters to create our primary analysis dataset:

1. **Primary outcomes**: Select only the primary instrument and timepoint for each study
2. **Study design**: Exclude post-crossover data
3. **Outcome type**: Include only endpoint data (mean/SD/N)
4. **Dosing**: Exclude medium-dose arms from multi-arm studies (Mithoefer 2018, Ot'alora 2018)

The resulting `data_main` dataframe contains the filtered data ready for our primary meta-analysis.

```{r filter}
data_main <- data %>%
  filterPoolingData(
    primary_instrument == "1",
    primary_timepoint == "1",
    is.na(post_crossover) | !Detect(post_crossover, "1"),
    outcome_type == "msd",
    !(Detect(study, "Mithoefer 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "75 mg")),
    !(Detect(study, "Mithoefer 2018") & (Detect(multi_arm1, "75 mg") & !is.na(multi_arm2))),
    !(Detect(study, "Ot'alora 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "100 mg")),
    !(Detect(study, "Ot'alora 2018") & (Detect(multi_arm1, "100 mg") & !is.na(multi_arm2)))
  )
```

## Results

### Primary Meta-Analysis

We conduct the main meta-analysis using the `runMetaAnalysis` function from `metapsyTools`.
This analysis pools all studies in our filtered dataset to estimate the overall effect of MDMA on PTSD severity.

**Key specifications:**

- **Effect size**: Hedges' g (standardized mean difference)

- **Model**: Random-effects meta-analysis using REML estimator

- **Adjustments**: Knapp-Hartung adjustment for significance tests


The results include the pooled effect size, confidence intervals, heterogeneity statistics, and the meta-analysis model object.

```{r primary-meta-analysis, message=FALSE}
# Run meta-analysis

main_results <- runMetaAnalysis(data_main,
  which.run = c("overall"),

  # Specify statistical parameters
  es.measure = "g", # Hedges' g
  method.tau = "REML",
  method.tau.ci = "Q-Profile",
  hakn = TRUE, # Knapp-Hartung adjustment

  # Specify variables
  study.var = "study",
  arm.var.1 = "condition_arm1",
  arm.var.2 = "condition_arm2",
  measure.var = "instrument",
  w1.var = "n_arm1",
  w2.var = "n_arm2",
  time.var = "time_days",
  round.digits = 2
)

summary(main_results$model.overall)

# Create simple forest plot of results

plot(
  main_results,
  which = "overall"
)
```


The primary meta-analysis on continuous outcomes in the 6 studies included in the main model showed a statistically significant reduction in PTSD scores with MDMA treatment as compared to control conditions, with small between-study heterogeneity.

```{r main continuous forest plot for indesign, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/fig2_mdmaptsd.png"), res = 315, width = 4500, height = 1500)

meta::forest(main_results$model.overall,
  sortvar = main_results$model.overall$data$year,
  leftcols = c("studlab", "condition_arm1", "dose_arm1", "n_arm1", "mean_arm1", "sd_arm1", "condition_arm2", "dose_arm2", "n_arm2", "mean_arm2", "sd_arm2"),
  leftlabs = c("Study", "Drug", "Dose", "N", "Mean", "SD", "Drug", "Dose", "N", "Mean", "SD"),
  fontsize = 9,
  col.square = "#000080",
  col.diamond = "#000080",
  col.predict = "gray",
  fontfamily = "Arial",
  colgap.forest = "2cm",
  xlim = c(-4.5, 2),
  label.left = "Favors intervention",
  label.right = "Favors control",
  smlab = "SMD"
)

dev.off()
```


### Publication Bias Assessment

We assess potential publication bias using both visual (funnel plot) and statistical (Egger's test) methods.

```{r eggertest}
# Run Egger's test
eggers.test(main_results$model.overall)
```
Egger's test did not indicate small-study effects/publication bias.


```{r funnelplot, message=FALSE, results='hide'}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/final/SI_Fig_01.png"), res = 315, width = 2500, height = 1500)
funnel(main_results$model.overall,
  studlab = TRUE, # can also use vector with study labels
  cex.studlab = 0.7, # adjust size of study labels
  cex = 0.7, # axis tick labels and point size
  cex.axis = 0.7, # axis number label size
  cex.lab = 0.7, # axis title (xlab, ylab) size
  cex.main = 0.95, # main title size
  xlim = c(-3, 0.2),
  col = "steelblue",
  pch = 19, # bold solid circle
  bg = "white",
  xlab = "Standardized Mean Difference (SMD)",
  ylab = "Standard Error (SE)",
  main = "Funnel Plot of Main Model Continuous Outcomes",
  las = 1
)
dev.off()
```

![](/analysis/mdmaptsd/paperfigs/final/SI_Fig_01.png)
Visual inspection of the funnel plot reveals limited asymmetry, and the Egger's test did not find small study effects, implying minimal evidence of publication bias.



### Three-level correlated and hierarchical effects (CHE) meta-analysis

We conduct a three-level correlated and hierarchical effects (CHE) meta-analysis to examine how the effect of MDMA changes over time.
This approach accounts for the hierarchical structure of the data (multiple timepoints within studies) and potential correlations between timepoints.

```{r che, message=FALSE}
# Select data for the CHE meta-analysis
data_time <- data %>%
  filterPoolingData(
    primary_instrument == "1",
    post_crossover == 0 | is.na(post_crossover),
    is.na(post_crossover) | !Detect(post_crossover, "1"),
    outcome_type == "msd",
    !(Detect(study, "Mithoefer 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "75 mg")),
    !(Detect(study, "Ot'alora 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "100 mg"))
  )

# Re-write some data for plotting
data_time$dose_arm1 <- as.numeric(gsub("mg", "", data_time$dose_arm1))
data_time$study[data_time$study == "Mithoefer 2018" & data_time$multi_arm1 == "75 mg"] <- "Mithoefer 2018 1"
data_time$study[data_time$study == "Mithoefer 2018" & data_time$multi_arm1 == "125 mg"] <- "Mithoefer 2018 2"
data_time$study[data_time$study == "Ot'alora 2018" & data_time$multi_arm1 == "100 mg"] <- "Ot'alora 2018 1"
data_time$study[data_time$study == "Ot'alora 2018" & data_time$multi_arm1 == "125 mg"] <- "Ot'alora 2018 2"

time_results <- runMetaAnalysis(data_time,
  which.run = "threelevel.che",
  # Specify statistical parameters
  es.measure = "g", # Hedges' g
  method.tau = "REML",
  method.tau.ci = "Q-Profile", # N/A for three-level models
  # i2.ci.boot = TRUE, # Need to use bootstrapping to get het. CI on three-level
  hakn = TRUE, # Knapp-Hartung adjustment

  # Specify variables
  study.var = "study",
  arm.var.1 = "condition_arm1",
  arm.var.2 = "condition_arm2",
  measure.var = "instrument",
  w1.var = "n_arm1",
  w2.var = "n_arm2",
  time.var = "dose_days",
  round.digits = 2
)

summary(time_results$model.threelevel.che)

plot(
  time_results,
  which = "threelevel.che"
)
```

```{r save plot, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/three_level_regression_forest.png"), res = 315, width = 4500, height = 1500)
plot(
  time_results,
  which = "threelevel.che",
  leftcols = c("studlab", "n_dosing_sessions", "dose_arm1", "cumulative_dose_arm1", "dose_weeks"),
  leftlabs = c("Study", "Dosing Session", "Dose (mg)", "Cumulative Dose (mg)", "Time (weeks)"),
)
dev.off()
```

The three-level CHE model reveals an overall significant decrease in PTSD scores under MDMA compared to control conditions.

#### Meta-Regression

We perform two separate meta-regressions to examine the relationship between dose and treatment effect:

##### 1. Number of dosing sessions

First, we examine the relationship between the number of dosing sessions and treatment effect.

```{r meta-regression n_dosing_sessions, message=FALSE, warning=FALSE}
reg <- metaRegression(time_results$model.threelevel.che, ~n_dosing_sessions)
reg
```
```{r plot-meta-regression session, message=FALSE, warning=FALSE, results=FALSE, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/dosing_sessions_regression.png"), res = 315, width = 3000, height = 2200)

par(
  cex.lab = 1.8, # axis titles (xlab, ylab)
  cex.axis = 1.5, # tick labels
  mar = c(5.5, 5.0, 3, 1.5) # bottom, left, top, right
)

regplot(reg, mod = "n_dosing_sessions", xlab = "Number of dosing sessions", ylab = "Hedges' g")

tab <- coef(summary(reg))
p_mod <- tab["n_dosing_sessions", "pval"]
slope <- tab["n_dosing_sessions", "estimate"]
# print(p_mod)

mtext(
  bquote(
    italic(beta) == .(format(signif(slope, digits = 1), scientific = FALSE)) * "," ~
      italic(p) == .(format.pval(p_mod, digits = 2, eps = 0.001))
  ),
  side = 3, line = 1, adj = 1, cex = 1.6
)

dev.off()
```

![](/analysis/mdmaptsd/paperfigs/dosing_sessions_regression.png)

The largest between-group difference in PTSD scores occurs after the first dosing session (Hedges’ *g* \= \-0.39), while additional sessions increase this difference by \-0.20 SMD.

##### 2. Cumulative dose

We also examine the relationship between the cumulative dose and treatment effect.
Cumulative dose is the total amount of MDMA taken by the participant (excluding booster doses for simplicity - all studies offered booster doses partway through the dosing sessions).
```{r meta-regression cumulative, message=FALSE, warning=FALSE}
reg <- metaRegression(time_results$model.threelevel.che, ~cumulative_dose_arm1)
reg
```
```{r plot-meta-regression cumulative, message=FALSE, warning=FALSE, results=FALSE, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/cumulative_dose.png"), res = 315, width = 3000, height = 2200)

par(
  cex.lab = 1.8, # axis titles (xlab, ylab)
  cex.axis = 1.5, # tick labels
  mar = c(5.5, 5.0, 3, 1.5) # bottom, left, top, right
)

regplot(reg, mod = "cumulative_dose_arm1", xlab = "Cumulative dose (mg)", ylab = "Hedges' g")

tab <- coef(summary(reg))
p_mod <- tab["cumulative_dose_arm1", "pval"]
slope <- tab["cumulative_dose_arm1", "estimate"]

mtext(
  bquote(
    italic(beta) == .(format(signif(slope, digits = 1), scientific = FALSE)) * "," ~
      italic(p) == .(format.pval(p_mod, digits = 2, eps = 0.001))
  ),
  side = 3, line = 1, adj = 1, cex = 1.6
)

dev.off()
```

![](/analysis/mdmaptsd/paperfigs/cumulative_dose.png)

Here, while the slope is small (Hedges’ *g* \= \-0.002), this is per mg of MDMA.
This comes out to about -0.20 SMD per 100 mg of MDMA.


### Secondary outcomes

In addition to continuous PTSD severity scores, we also analyze dichotomous outcomes including response and remission rates of PTSD scores and secondary continuous self-reported depression outcomes.
These analyses provide complementary information about the clinical significance of MDMA treatment.

#### Response Rate Analysis

We first analyze response rates, defined as the proportion of participants achieving a clinically meaningful reduction in PTSD symptoms.

```{r response model, message=FALSE}
# Get response data
data_response <- data %>%
  filterPoolingData(
    primary_instrument == "1",
    primary_timepoint == "1",
    is.na(post_crossover) | !Detect(post_crossover, "1"),
    outcome_type == "response",
    !(Detect(study, "Mithoefer 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "75 mg")),
    !(Detect(study, "Mithoefer 2018") & (Detect(multi_arm1, "75 mg") & !is.na(multi_arm2))),
    !(Detect(study, "Ot'alora 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "100 mg")),
    !(Detect(study, "Ot'alora 2018") & (Detect(multi_arm1, "100 mg") & !is.na(multi_arm2)))
  )

# Run meta-analysis

response_results <- runMetaAnalysis(data_response,
  which.run = "overall",
  es.measure = "RR", # risk ratio
  es.type = "raw",
  method.tau = "PM",
  method.tau.ci = "Q-Profile",
  hakn = TRUE, # Knapp-Hartung adjustement

  # Specify variables
  study.var = "study",
  arm.var.1 = "condition_arm1",
  arm.var.2 = "condition_arm2",
  measure.var = "instrument",
  w1.var = "n_arm1",
  w2.var = "n_arm2",
  time.var = "time_weeks",
  round.digits = 2
)

summary(response_results$model.overall)
# Create simple forest plot of response results

meta::forest(
  response_results$model.overall,
  sortvar = response_results$model.overall$data$year,
  xlab = "Log RR (95% CI)",
  leftlabs = c("Study", "Log RR"),
  layout = "JAMA"
)
```

Our meta-analysis shows statistically significant greater treatment response with MDMA compared to control conditions.


#### Remission Rate Analysis

We also analyze remission rates, defined as the proportion of participants achieving full remission of depressive symptoms.

```{r remission model, message=FALSE}
# Get remission data
data_remission <- data %>%
  filterPoolingData(
    primary_instrument == "1",
    primary_timepoint == "1",
    is.na(post_crossover) | !Detect(post_crossover, "1"),
    outcome_type == "remission",
    !(Detect(study, "Mithoefer 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "75 mg")),
    !(Detect(study, "Mithoefer 2018") & (Detect(multi_arm1, "75 mg") & !is.na(multi_arm2))),
    !(Detect(study, "Ot'alora 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "100 mg")),
    !(Detect(study, "Ot'alora 2018") & (Detect(multi_arm1, "100 mg") & !is.na(multi_arm2)))
  )

# Run meta-analysis

remission_results <- runMetaAnalysis(data_remission,
  which.run = "overall",
  es.measure = "RR", # risk ratio
  es.type = "raw",
  method.tau = "PM",
  method.tau.ci = "Q-Profile",
  hakn = TRUE, # Knapp-Hartung adjustement

  # Specify variables
  study.var = "study",
  arm.var.1 = "condition_arm1",
  arm.var.2 = "condition_arm2",
  measure.var = "instrument",
  w1.var = "n_arm1",
  w2.var = "n_arm2",
  time.var = "time_weeks",
  round.digits = 2
)

summary(remission_results$model.overall)
# Create simple forest plot of remission results

meta::forest(
  remission_results$model.overall,
  sortvar = remission_results$model.overall$data$year,
  xlab = "Log RR (95% CI)",
  leftlabs = c("Study", "Log RR"),
  layout = "JAMA"
)
```

Our meta-analysis shows statistically significant higher remission rates with MDMA compared to control conditions.

```{r forest meta response for indesign, include=FALSE}
### forest plot for response

# grab heterogeneity values
tau2 <- response_results$model.overall$tau2
lower_tau2 <- response_results$model.overall$lower.tau2
upper_tau2 <- response_results$model.overall$upper.tau2
I2 <- response_results$model.overall$I2
lower_I2 <- response_results$model.overall$lower.I2
upper_I2 <- response_results$model.overall$upper.I2
pval <- response_results$model.overall$pval.Q

# format heterogeneity text
heterogeneity_text <- sprintf(
  "Heterogeneity: I² = %.2f%% [%.2f%%, %.2f%%], τ² = %.2f [%.2f, %.2f], p = %.3f",
  I2 * 100, lower_I2 * 100, upper_I2 * 100,
  tau2, lower_tau2, upper_tau2,
  pval
)

png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/response_forest_plot_meta_mdmaptsd.png"), res = 315, width = 4500, height = 1500)


meta::forest(response_results$model.overall,
  sortvar = response_results$model.overall$data$year,
  leftcols = c("studlab", "dose_arm1", "condition_arm1", "event_arm1", "totaln_arm1", "dose_arm2", "condition_arm2", "event_arm2", "totaln_arm2"),
  leftlabs = c("Study", "Dose", "Drug", "Number of Events", "Total", "Dose", "Drug", "Number of Events", "Total"),
  rightlabs = c("Log RR", "95%-CI", "Weight"),
  fontsize = 9,
  col.square = "#000080",
  col.diamond = "#000080",
  col.predict = "gray",
  fontfamily = "Arial",
  colgap.forest = "2cm",
  xlim = c(0.2, 120),
  label.left = "Favors control",
  label.right = "Favors intervention",
  smlab = "Log Risk Ratio"
)

# add heterogeneity text at the bottom
grid::grid.text(
  label = heterogeneity_text,
  x = 0.5, # Centered horizontally (normalized coordinates)
  y = unit(1.5, "lines"), # Slightly below the plot
  just = "center",
  gp = grid::gpar(fontsize = 9, fontfamily = "Arial")
)

dev.off()
```
```{r forest meta remission for indesign, include=FALSE}
### forest plot for remission

# grab heterogeneity values
tau2 <- remission_results$model.overall$tau2
lower_tau2 <- remission_results$model.overall$lower.tau2
upper_tau2 <- remission_results$model.overall$upper.tau2
I2 <- remission_results$model.overall$I2
lower_I2 <- remission_results$model.overall$lower.I2
upper_I2 <- remission_results$model.overall$upper.I2
pval <- remission_results$model.overall$pval.Q

# format heterogeneity text
heterogeneity_text <- sprintf(
  "Heterogeneity: I² = %.2f%% [%.2f%%, %.2f%%], τ² = %.2f [%.2f, %.2f], p = %.3f",
  I2 * 100, lower_I2 * 100, upper_I2 * 100,
  tau2, lower_tau2, upper_tau2,
  pval
)

png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/remission_forest_plot_meta_mdmaptsd.png"), res = 315, width = 4500, height = 1500)


meta::forest(remission_results$model.overall,
  sortvar = remission_results$model.overall$data$year,
  leftcols = c("studlab", "dose_arm1", "condition_arm1", "event_arm1", "totaln_arm1", "dose_arm2", "condition_arm2", "event_arm2", "totaln_arm2"),
  leftlabs = c("Study", "Dose", "Drug", "Number of Events", "Total", "Dose", "Drug", "Number of Events", "Total"),
  rightlabs = c("Log RR", "95%-CI", "Weight"),
  fontsize = 9,
  col.square = "#000080",
  col.diamond = "#000080",
  col.predict = "gray",
  fontfamily = "Arial",
  colgap.forest = "2cm",
  xlim = c(0.2, 55),
  label.left = "Favors control",
  label.right = "Favors intervention",
  smlab = "Log Risk Ratio"
)

# add heterogeneity text at the bottom
grid::grid.text(
  label = heterogeneity_text,
  x = 0.5, # Centered horizontally (normalized coordinates)
  y = unit(1.5, "lines"), # Slightly below the plot
  just = "center",
  gp = grid::gpar(fontsize = 9, fontfamily = "Arial")
)

dev.off()
```

#### Secondary outcome - depression

Our depression outcomes are stored on a separate local database.

```{r depression model}
data2 <- read_csv("~/Documents/GIT/psypres/MDMAPTSD/data/data.csv") # for parker
# data2 <- read_csv("/Users/bsevchik/Documents/GitHub/psypres/MDMAPTSD/data/data.csv") # for brooke
data2 <- data2 %>%
  calculateEffectSizes(
    vars.for.id = c(
      "study", "outcome_type",
      "instrument", "study_time_point",
      "time_weeks",
      "rating"
    ),
  )

# Select depression data
data_depression <- data2 %>%
  filterPoolingData(
    primary_timepoint == "1",
    is.na(post_crossover) | !Detect(post_crossover, "1"),
    !(Detect(study, "Mithoefer 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "75 mg")),
    !(Detect(study, "Mithoefer 2018") & (Detect(multi_arm1, "75 mg") & !is.na(multi_arm2))),
    !(Detect(study, "Ot'alora 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "100 mg")),
    !(Detect(study, "Ot'alora 2018") & (Detect(multi_arm1, "100 mg") & !is.na(multi_arm2))),
    Detect(instrument_symptom, "depression"),
    outcome_type == "msd"
  ) %>%
  filterPriorityRule(instrument = c("bdi-ii", "bid-1a", "bdi", "qids-sr", "hads-d", "smdds", "hads"))

# Run meta-analysis
dep_results <- runMetaAnalysis(data_depression,
  which.run = c("overall"),
  # Specify statistical parameters
  es.measure = "g", # Hedges' g
  method.tau = "REML",
  method.tau.ci = "Q-Profile", # N/A for three-level models
  # i2.ci.boot = TRUE, # Need to use bootstrapping to get het. CI on three-level
  hakn = TRUE, # Knapp-Hartung adjustment

  # Specify variables
  study.var = "study",
  arm.var.1 = "condition_arm1",
  arm.var.2 = "condition_arm2",
  measure.var = "instrument",
  w1.var = "n_arm1",
  w2.var = "n_arm2",
  time.var = "time_days",
  round.digits = 2
)

summary(dep_results$model.overall)

# Create simple forest plot of results

plot(
  dep_results,
  which = "overall"
)
```
```{r depression continuous forest plot for indesign, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/depression_mdmaptsd.png"), res = 315, width = 4500, height = 1500)

meta::forest(dep_results$model.overall,
  sortvar = dep_results$model.overall$data$year,
  leftcols = c("studlab", "condition_arm1", "dose_arm1", "n_arm1", "mean_arm1", "sd_arm1", "condition_arm2", "dose_arm2", "n_arm2", "mean_arm2", "sd_arm2"),
  leftlabs = c("Study", "Drug", "Dose", "N", "Mean", "SD", "Drug", "Dose", "N", "Mean", "SD"),
  fontsize = 9,
  col.square = "#000080",
  col.diamond = "#000080",
  col.predict = "gray",
  fontfamily = "Arial",
  colgap.forest = "2cm",
  xlim = c(-4.5, 2),
  label.left = "Favors intervention",
  label.right = "Favors control",
  smlab = "SMD"
)

dev.off()
```

### Sensitivity Analyses

We conduct comprehensive sensitivity analyses to examine the robustness of our findings.

These analyses include:


- In the multi-arm studies (Mithoefer 2018 and Ot'alora 2018) replace high-dose intervention with medium-dose intervention

- Fixed-effects models for primary continuous outcomes and response and remission rates

- A Bayesian analysis of our primary results

- Within-study correlation coefficient sweep for three-level CHE model

#### Medium dose comparison and fixed effects analyses

```{r subgroup-and-sensitivity-data-filtering}
# Build a dataframe for the first sensitivity analysis
data_medium_dose <- data %>%
  filterPoolingData(
    primary_instrument == "1",
    primary_timepoint == "1",
    is.na(post_crossover) | !Detect(post_crossover, "1"),
    outcome_type == "msd",
    !(Detect(study, "Mithoefer 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "125 mg")),
    !(Detect(study, "Mithoefer 2018") & (Detect(multi_arm1, "125 mg") & !is.na(multi_arm2))),
    !(Detect(study, "Ot'alora 2018") & (!is.na(multi_arm1)) & Detect(multi_arm2, "125 mg")),
    !(Detect(study, "Ot'alora 2018") & (Detect(multi_arm1, "125 mg") & !is.na(multi_arm2)))
  )
```

Now we can use `metapsyTools` replacement functions for quickly looking running some sensitivity analyses.

```{r run individual meta analyses for paper, warning=FALSE, message=FALSE}
# Use metapsyTools' replacement and rerun functions for quickly changing parameters
medium <- main_results # copy the main model
data(medium) <- data_medium_dose # replace the dataframe in the new model
medium <- rerun(medium) # re-run the model
medium

# Create simple forest plot of results
plot(
  medium,
  which = "overall"
)

fixed_continuous <- main_results
method.tau(fixed_continuous) <- "FE" # for this sensitivity analysis, we keep data the same but change parameters
hakn(fixed_continuous) <- FALSE
fixed_continuous <- rerun(fixed_continuous)
fixed_continuous

fixed_response <- response_results
method.tau(fixed_response) <- "FE"
hakn(fixed_response) <- FALSE
fixed_response <- rerun(fixed_response)
fixed_response

fixed_remission <- remission_results
method.tau(fixed_remission) <- "FE"
hakn(fixed_remission) <- FALSE
fixed_remission <- rerun(fixed_remission)
fixed_remission
```

Our medium dose comparison yielded similar results to the high dose comparison.
Our fixed effects models yielded results that were in line with the random effects models.

```{r main medium dose forest plot for indesign, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/medium_dose_mdmaptsd.png"), res = 315, width = 4500, height = 1500)

meta::forest(medium$model.overall,
  sortvar = medium$model.overall$data$year,
  leftcols = c("studlab", "condition_arm1", "dose_arm1", "n_arm1", "mean_arm1", "sd_arm1", "condition_arm2", "dose_arm2", "n_arm2", "mean_arm2", "sd_arm2"),
  leftlabs = c("Study", "Drug", "Dose", "N", "Mean", "SD", "Drug", "Dose", "N", "Mean", "SD"),
  fontsize = 9,
  col.square = "#000080",
  col.diamond = "#000080",
  col.predict = "gray",
  fontfamily = "Arial",
  colgap.forest = "2cm",
  xlim = c(-4.5, 2),
  label.left = "Favors intervention",
  label.right = "Favors control",
  smlab = "SMD"
)

dev.off()
```

#### Bayesian implementation

We implement our main model using a bayesian framework.
We do this using the `bayesmeta` package using "weakly informative prior distributions".

Parameters:
- A normal prior distribution with a 95% probability that the pooled estimate falls between -2 and 2.
- A half-normal prior distribution for tau, with an s.d. of 0.5

```{r bayes}
bayes <- bayesmeta(
  data_main$.g,
  data_main$.g_se,
  mu.prior = c("mean" = 0, "sd" = 1), # asserts a 95% prior b/n -2 and 2
  tau.prior = function(t) dhalfnormal(t, scale = 0.5)
)
bayes
```

Above we can see the characteristics of the marginal posterior distributions of tau and mu (the pooled estimate).
The model finds that the 95% interval of the true effect lies between -1.05 and -0.36.
```{r bayes mu, include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/bayesmu.png"), res = 315, width = 1500, height = 1000)

plot.bayesmeta(
  bayes,
  prior = TRUE,
  which = 3
)

dev.off()

png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/bayestau.png"), res = 315, width = 1500, height = 1000)

plot.bayesmeta(
  bayes,
  prior = TRUE,
  which = 4
)

dev.off()
```
We can visualize each posterior probability distribution (solid line), along with the priors (dashed) below:
![](/analysis/mdmaptsd/paperfigs/final/SI_Fig_03.png)

#### Sweep the within-study correlation coefficient for the three-level CHE

The CHE model assumes that there is a known correlation "rho" between effect sizes in the same study; and that "rho" has the same value within and across all studies in our meta-analysis (the “constant sampling correlation” assumption, J. E. Pustejovsky and Tipton 2021).
While these authors have reported that "meta-regression coefficient estimates were largely insensitive to assuming different values of rho between 0.0 and 0.8", our default choice of rho = 0.6 in metapsyTools is nonetheless, a guess.
It is therefore generally recommended to run sensitivity analyses for varying values of rho:

```{r sweep within study rho, message=FALSE, warning=FALSE, results='hide'}
# sweep rho in the CHE model for r = seq(0, 1, 0.1)
rho_seq <- seq(0, 1, 0.1)
i <- 1
g_sweep <- numeric(length(rho_seq))
g_ci_lwr <- numeric(length(rho_seq)) # Initialize the vector
g_ci_upr <- numeric(length(rho_seq)) # Initialize the vector

for (rho in rho_seq) {
  time_results_sweep <- runMetaAnalysis(data_time,
    which.run = "threelevel.che",
    # Specify statistical parameters
    es.measure = "g", # Hedges' g
    method.tau = "REML",
    method.tau.ci = "Q-Profile", # N/A for three-level models
    hakn = TRUE, # Knapp-Hartung adjustment
    rho.within.study = rho,
    # Specify variables
    study.var = "study",
    arm.var.1 = "condition_arm1",
    arm.var.2 = "condition_arm2",
    measure.var = "instrument",
    w1.var = "n_arm1",
    w2.var = "n_arm2",
    time.var = "time_days",
    round.digits = 2
  )

  g_sweep[i] <- time_results_sweep$summary$g[2]
  g_ci <- as.numeric(
    strsplit(gsub("\\[|\\]", "", time_results_sweep$summary$g.ci[2]), ";")[[1]]
  )
  g_ci_lwr[i] <- g_ci[1]
  g_ci_upr[i] <- g_ci[2]
  i <- i + 1
}
```
```{r rho sweep, message=FALSE, results='hide', fig.show='hold', include=FALSE}
png(filename = file.path(basedir, "analysis/mdmaptsd/paperfigs/final/SI_Fig_04.png"), res = 315, width = 2500, height = 1500)
# plot the results (base R with shaded CI ribbon)
y_vals <- c(g_ci_lwr, g_ci_upr, g_sweep)
y_finite <- y_vals[is.finite(y_vals)]
y_range <- suppressWarnings(range(y_finite))
if (!all(is.finite(y_range))) y_range <- c(-1, 1)

{
  plot(rho_seq, g_sweep,
    type = "n",
    xlab = "rho", ylab = "Hedges' g",
    xlim = range(rho_seq, na.rm = TRUE),
    ylim = y_range
  )

  mask_ci <- is.finite(g_ci_lwr) & is.finite(g_ci_upr) & is.finite(rho_seq)
  if (sum(mask_ci) >= 2) {
    polygon(c(rho_seq[mask_ci], rev(rho_seq[mask_ci])),
      c(g_ci_lwr[mask_ci], rev(g_ci_upr[mask_ci])),
      col = grDevices::adjustcolor("red", alpha.f = 0.2),
      border = NA
    )
  }

  lines(rho_seq, g_sweep, col = "blue", lwd = 2)
  lines(rho_seq, g_ci_lwr, col = "red", lty = 2)
  lines(rho_seq, g_ci_upr, col = "red", lty = 2)
}
dev.off()
```

![](/analysis/mdmaptsd/paperfigs/final/SI_Fig_04.png)

The main effect size is not sensitive to the within-study correlation coefficient.
```{r calculating n for each study at timepoint, include=FALSE}
# Create function to get total n at each timepoint

total_n <- function(df) {
  total <- sum(df$n_arm1 + df$n_arm2, na.rm = TRUE)
  return(total)
}

total_n_dichotomous <- function(df) {
  total <- sum(df$totaln_arm1 + df$totaln_arm2, na.rm = TRUE)
  return(total)
}


# Apply function to different data frames
total_data_main <- total_n(data_main)
print(paste("main n =", total_data_main))

total_data_medium_dose <- total_n(data_medium_dose)
print(paste("sens n =", total_data_medium_dose))

total_data_response <- total_n_dichotomous(data_response)
print(paste("response n =", total_data_response))

total_data_remission <- total_n_dichotomous(data_remission)
print(paste("remission n =", total_data_remission))

total_data_dep <- total_n(data_depression)
print(paste("dep n =", total_data_dep))
```

### Summary and Conclusions

This comprehensive meta-analysis provides promising evidence regarding the efficacy of MDMA for treating PTSD, but should be interpreted with caution.

The analysis includes:

1. **Primary analysis** of continuous PTSD severity outcomes using standardized mean differences
2. **Dose-response analysis** examining how treatment effects are impacted by number of dosing sessions and cumulative dose
3. **Dichotomous outcomes analysis** of response and remission rates
4. **Secondary outcomes analysis** of self-reported depression outcomes
5. **Extensive sensitivity analyses** to examine robustness

The results demonstrate consistent evidence for the efficacy of MDMA in reducing PTSD severity, with effects showing robustness across various sensitivity analyses.
However, given the small number of studies eligible to include in our meta-analysis and limitations such as the potential for functional unblinding and expectancy effects, results should be interpreted with caution.

